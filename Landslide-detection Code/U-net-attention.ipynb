{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6985382,"sourceType":"datasetVersion","datasetId":4014602}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install tensorflow","metadata":{"id":"ty-4hAzq3cEL","outputId":"d9b2db51-b11c-4f2d-8827-afe11b9c6ab2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install matplotlib","metadata":{"id":"Wt2rwZ803he4","outputId":"9b6c702f-f9fa-4f18-b21e-cc59f48862d3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport h5py\nimport glob\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport tensorflow as tf","metadata":{"id":"j5lT58T03kfj","execution":{"iopub.status.busy":"2023-11-17T05:27:02.311520Z","iopub.execute_input":"2023-11-17T05:27:02.312723Z","iopub.status.idle":"2023-11-17T05:27:21.415187Z","shell.execute_reply.started":"2023-11-17T05:27:02.312678Z","shell.execute_reply":"2023-11-17T05:27:21.414257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_single = r\"/kaggle/input/lanslidedetection/img/image_2000.h5\"\npath_single_mask = r'/kaggle/input/lanslidedetection/mask/mask_2000.h5'","metadata":{"id":"FC3cTnUA8q0G","execution":{"iopub.status.busy":"2023-11-17T05:27:21.416966Z","iopub.execute_input":"2023-11-17T05:27:21.417571Z","iopub.status.idle":"2023-11-17T05:27:21.422356Z","shell.execute_reply.started":"2023-11-17T05:27:21.417539Z","shell.execute_reply":"2023-11-17T05:27:21.421125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f_data = np.zeros((1, 128,128, 3))\nwith h5py.File(path_single) as hdf:\n    ls = list(hdf.keys())\n    print(\"ls\", ls)\n    data = np.array(hdf.get('img'))\n    print(\"input data shape:\", data.shape)\n    plt.imshow(data[:, :, 3:0:-1])\n    plt.show()\n\n    data_red = data[:, :, 3]\n    data_green = data[:, :, 2]\n    data_blue = data[:, :, 1]\n    data_nir = data[:, :, 7]\n    data_rgb = data[:, :, 3:0:-1]\n    data_ndvi = np.divide(data_nir - data_red,np.add(data_nir, data_red))\n    f_data[0, :, :, 0] =data_ndvi\n    f_data[0, :, :, 1] = data[:, :, 12]\n    f_data[0, :, :, 2] = data[:, :, 13]\n\n    print(\"data ndvi shape \", data_ndvi.shape, \"f_data shape: \", f_data.shape)\n    plt.imshow(data_ndvi)","metadata":{"id":"hgodWtKV85YQ","outputId":"924c1c98-bea9-4676-bbf2-f19c153dc959","execution":{"iopub.status.busy":"2023-11-17T05:27:21.424012Z","iopub.execute_input":"2023-11-17T05:27:21.424563Z","iopub.status.idle":"2023-11-17T05:27:22.330587Z","shell.execute_reply.started":"2023-11-17T05:27:21.424517Z","shell.execute_reply":"2023-11-17T05:27:22.329541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with h5py.File(path_single_mask) as hdf:\n    ls = list(hdf.keys())\n    print(\"ls\", ls)\n    data = np.array(hdf.get('mask'))\n    print(\"input data shape:\", data.shape)\n    plt.imshow(data)","metadata":{"id":"DdR8XEWx_EeN","outputId":"b7634223-4128-4685-9d69-e42e0ed1b958","execution":{"iopub.status.busy":"2023-11-17T05:27:22.333477Z","iopub.execute_input":"2023-11-17T05:27:22.334257Z","iopub.status.idle":"2023-11-17T05:27:22.679928Z","shell.execute_reply.started":"2023-11-17T05:27:22.334217Z","shell.execute_reply":"2023-11-17T05:27:22.678867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_PATH = r\"/kaggle/input/lanslidedetection/img/*.h5\"\nTRAIN_MASK = r'/kaggle/input/lanslidedetection/mask/*.h5'\n\nTRAIN_XX = np.zeros((3799, 128, 128, 6))\nTRAIN_YY = np.zeros((3799, 128, 128, 1))\nall_train = sorted(glob.glob(TRAIN_PATH))\nall_mask = sorted(glob.glob(TRAIN_MASK))","metadata":{"id":"9_UylP8sBu3e","execution":{"iopub.status.busy":"2023-11-17T05:27:22.681172Z","iopub.execute_input":"2023-11-17T05:27:22.681460Z","iopub.status.idle":"2023-11-17T05:27:22.959207Z","shell.execute_reply.started":"2023-11-17T05:27:22.681435Z","shell.execute_reply":"2023-11-17T05:27:22.958321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#testing for google colab GPU\nimport tensorflow as tf\ntf.test.gpu_device_name()","metadata":{"id":"HAyoe99ZGh7d","outputId":"49423eec-dba9-435e-e0f6-0c3c8c206c59","execution":{"iopub.status.busy":"2023-11-17T05:27:22.960722Z","iopub.execute_input":"2023-11-17T05:27:22.961012Z","iopub.status.idle":"2023-11-17T05:27:28.245524Z","shell.execute_reply.started":"2023-11-17T05:27:22.960987Z","shell.execute_reply":"2023-11-17T05:27:28.244222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, (img, mask) in enumerate(zip(all_train, all_mask)):\n    #print(i, img, mask)\n    with h5py.File(img) as hdf:\n        ls = list(hdf.keys())\n        data = np.array(hdf.get('img'))\n\n        # assign 0 for the nan value\n        data[np.isnan(data)] = 0.000001\n\n        # to normalize the data\n        mid_rgb = data[:, :, 1:4].max() / 2.0\n        mid_slope = data[:, :, 12].max() / 2.0\n        mid_elevation = data[:, :, 13].max() / 2.0\n\n        # ndvi calculation\n        data_red = data[:, :, 3]\n        data_nir = data[:, :, 7]\n        data_ndvi = np.divide(data_nir - data_red,np.add(data_nir, data_red))\n\n        # final array\n        TRAIN_XX[i, :, :, 0] = 1 - data[:, :, 3] / mid_rgb  #RED\n        TRAIN_XX[i, :, :, 1] = 1 - data[:, :, 2] / mid_rgb #GREEN\n        TRAIN_XX[i, :, :, 2] = 1 - data[:, :, 1] / mid_rgb #BLUE\n        TRAIN_XX[i, :, :, 3] = data_ndvi #NDVI\n        TRAIN_XX[i, :, :, 4] = 1 - data[:, :, 12] / mid_slope #SLOPE\n        TRAIN_XX[i, :, :, 5] = 1 - data[:, :, 13] / mid_elevation #ELEVATION\n\n\n    with h5py.File(mask) as hdf:\n        ls = list(hdf.keys())\n        data=np.array(hdf.get('mask'))\n        #plt.imshow(data)\n        #plt.show()\n        TRAIN_YY[i, :, :, 0] = data\n","metadata":{"id":"Yyg0Xsw-HUPw","outputId":"683ceab2-0839-4fb2-8edf-d24b162d22d3","execution":{"iopub.status.busy":"2023-11-17T05:27:28.246930Z","iopub.execute_input":"2023-11-17T05:27:28.247545Z","iopub.status.idle":"2023-11-17T05:29:54.334315Z","shell.execute_reply.started":"2023-11-17T05:27:28.247515Z","shell.execute_reply":"2023-11-17T05:29:54.333191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_XX[np.isnan(TRAIN_XX)] = 0.000001\nprint(TRAIN_XX.min(), TRAIN_XX.max(), TRAIN_YY.min(), TRAIN_YY.max())","metadata":{"id":"uRQd3iYvJqax","outputId":"03c374c1-731d-414e-dae0-2c4939817bc1","execution":{"iopub.status.busy":"2023-11-17T05:29:54.335442Z","iopub.execute_input":"2023-11-17T05:29:54.335759Z","iopub.status.idle":"2023-11-17T05:29:55.352465Z","shell.execute_reply.started":"2023-11-17T05:29:54.335728Z","shell.execute_reply":"2023-11-17T05:29:55.351521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dice_loss(y_true, y_pred):\n  y_true = tf.cast(y_true, tf.float32)\n  y_pred = tf.math.sigmoid(y_pred)\n  numerator = 2 * tf.reduce_sum(y_true * y_pred)\n  denominator = tf.reduce_sum(y_true + y_pred)\n\n  return 1 - numerator / denominator","metadata":{"id":"PYSapN-rUscr","execution":{"iopub.status.busy":"2023-11-17T05:29:55.353781Z","iopub.execute_input":"2023-11-17T05:29:55.354185Z","iopub.status.idle":"2023-11-17T05:29:55.359435Z","shell.execute_reply.started":"2023-11-17T05:29:55.354142Z","shell.execute_reply":"2023-11-17T05:29:55.358466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img=234\nfig,(ax1,ax2, ax3, ax4, ax5)= plt.subplots(1,5,figsize=(15,10))\n\n\nax1.set_title(\"RGB image\")\nax2.set_title(\"NDVI\")\nax3.set_title(\"Slope\")\nax4.set_title(\"Elevation\")\nax5.set_title(\"Mask\")\nax1.imshow(TRAIN_XX[img, :, :, 0:3])\nax2.imshow(TRAIN_XX[img, :, :, 3])\nax3.imshow(TRAIN_XX[img, :, :, 4])\nax4.imshow(TRAIN_XX[img, :, :, 5])\nax5.imshow(TRAIN_YY[img, :, :, 0])","metadata":{"id":"4TEBmPoKpwmj","outputId":"de9eb3d7-c30a-4b9d-bb88-1e39e337d0ae","execution":{"iopub.status.busy":"2023-11-17T05:29:55.364813Z","iopub.execute_input":"2023-11-17T05:29:55.365542Z","iopub.status.idle":"2023-11-17T05:29:56.720366Z","shell.execute_reply.started":"2023-11-17T05:29:55.365506Z","shell.execute_reply":"2023-11-17T05:29:56.719299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note: Learn about NDVI, Slope and Elevation properly, Something is going wrong in thw split!!","metadata":{"id":"hltzGw3qqAYx"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split the data\nx_train, x_valid, y_train, y_valid = train_test_split(TRAIN_XX, TRAIN_YY, test_size=0.2, shuffle= True, random_state=42)","metadata":{"id":"hp0Auy6IqGZY","execution":{"iopub.status.busy":"2023-11-17T05:29:56.721890Z","iopub.execute_input":"2023-11-17T05:29:56.722229Z","iopub.status.idle":"2023-11-17T05:29:58.225078Z","shell.execute_reply.started":"2023-11-17T05:29:56.722204Z","shell.execute_reply":"2023-11-17T05:29:58.223888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img=1548\nfig,(ax1,ax2, ax3, ax4, ax5)= plt.subplots(1,5,figsize=(15,10))\n\nax1.set_title(\"RGB image\")\nax2.set_title(\"NDVI\")\nax3.set_title(\"Slope\")\nax4.set_title(\"Elevation\")\nax5.set_title(\"Mask\")\nax1.imshow(x_train[img, :, :, 0:3])\nax2.imshow(x_train[img, :, :, 3])\nax3.imshow(x_train[img, :, :, 4])\nax4.imshow(x_train[img, :, :, 5])\nax5.imshow(y_train[img, :, :, 0])","metadata":{"id":"O-0JOB_sqQos","outputId":"04f53fef-2ce3-477c-95d9-d1e7ae3f54af","execution":{"iopub.status.busy":"2023-11-17T05:29:58.226564Z","iopub.execute_input":"2023-11-17T05:29:58.226894Z","iopub.status.idle":"2023-11-17T05:29:59.341814Z","shell.execute_reply.started":"2023-11-17T05:29:58.226868Z","shell.execute_reply":"2023-11-17T05:29:59.340848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.shape, y_train.shape","metadata":{"id":"P9Eag16RqY-P","outputId":"509a767b-8cc2-4f88-8a29-a292dca99765","execution":{"iopub.status.busy":"2023-11-17T05:29:59.343356Z","iopub.execute_input":"2023-11-17T05:29:59.343780Z","iopub.status.idle":"2023-11-17T05:29:59.350715Z","shell.execute_reply.started":"2023-11-17T05:29:59.343735Z","shell.execute_reply":"2023-11-17T05:29:59.349642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to release some memory, delete the unnecessary variable\ndel TRAIN_XX\ndel TRAIN_YY\ndel all_train\ndel all_mask","metadata":{"id":"pQ3VwqNnqd07","execution":{"iopub.status.busy":"2023-11-17T05:29:59.351804Z","iopub.execute_input":"2023-11-17T05:29:59.352183Z","iopub.status.idle":"2023-11-17T05:29:59.571139Z","shell.execute_reply.started":"2023-11-17T05:29:59.352157Z","shell.execute_reply":"2023-11-17T05:29:59.569934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img=1548\nfig,(ax1,ax2, ax3, ax4)= plt.subplots(1,4,figsize=(15,10))\n\n\nax1.set_title(\"RGB image\")\nax2.set_title(\"NDVI\")\nax3.set_title(\"SLOPE\")\nax4.set_title(\"Mask\")\nax1.imshow(x_train[img, :, :, 0:3])\nax2.imshow(x_train[img, :, :, 3])\nax3.imshow(x_train[img, :, :, 4])\nax4.imshow(y_train[img, :, :, 0])","metadata":{"id":"mUenSLqbqllR","outputId":"e9b9c0e4-2a74-47b7-ff9d-00cf5655610b","execution":{"iopub.status.busy":"2023-11-17T05:29:59.572413Z","iopub.execute_input":"2023-11-17T05:29:59.572821Z","iopub.status.idle":"2023-11-17T05:30:00.625877Z","shell.execute_reply.started":"2023-11-17T05:29:59.572785Z","shell.execute_reply":"2023-11-17T05:30:00.624625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import backend as K\n\n# recall\ndef recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n\n# precision\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n\n#f1 score\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","metadata":{"id":"31QADv5hQOhK","execution":{"iopub.status.busy":"2023-11-17T05:30:00.627337Z","iopub.execute_input":"2023-11-17T05:30:00.627726Z","iopub.status.idle":"2023-11-17T05:30:00.866344Z","shell.execute_reply.started":"2023-11-17T05:30:00.627692Z","shell.execute_reply":"2023-11-17T05:30:00.865561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def channel_attention_module(x, ratio=8):\n    batch, _, _, channel = x.shape\n\n    ## Shared layers\n    l1 = Dense(channel//ratio, activation=\"relu\", use_bias=False)\n    l2 = Dense(channel, use_bias=False)\n\n    ## Global Average Pooling\n    x1 = GlobalAveragePooling2D()(x)\n    x1 = l1(x1)\n    x1 = l2(x1)\n\n    ## Global Max Pooling\n    x2 = GlobalMaxPooling2D()(x)\n    x2 = l1(x2)\n    x2 = l2(x2)\n\n    ## Add both the features and pass through sigmoid\n    feats = x1 + x2\n    feats = Activation(\"sigmoid\")(feats)\n    feats = Multiply()([x, feats])\n\n    return feats","metadata":{"execution":{"iopub.status.busy":"2023-11-17T05:30:00.867479Z","iopub.execute_input":"2023-11-17T05:30:00.867799Z","iopub.status.idle":"2023-11-17T05:30:00.875571Z","shell.execute_reply.started":"2023-11-17T05:30:00.867773Z","shell.execute_reply":"2023-11-17T05:30:00.874545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def spatial_attention_module(x):\n    ## Average Pooling\n    x1 = tf.reduce_mean(x, axis=-1)\n    x1 = tf.expand_dims(x1, axis=-1)\n\n    ## Max Pooling\n    x2 = tf.reduce_max(x, axis=-1)\n    x2 = tf.expand_dims(x2, axis=-1)\n\n    ## Concatenat both the features\n    feats = Concatenate()([x1, x2])\n    ## Conv layer\n    feats = Conv2D(1, kernel_size=7, padding=\"same\", activation=\"sigmoid\")(feats)\n    feats = Multiply()([x, feats])\n\n    return feats\n","metadata":{"execution":{"iopub.status.busy":"2023-11-17T05:30:00.877138Z","iopub.execute_input":"2023-11-17T05:30:00.877484Z","iopub.status.idle":"2023-11-17T05:30:00.896465Z","shell.execute_reply.started":"2023-11-17T05:30:00.877449Z","shell.execute_reply":"2023-11-17T05:30:00.895724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cbam(x):\n    x = channel_attention_module(x)\n    x = spatial_attention_module(x)\n    return x","metadata":{"execution":{"iopub.status.busy":"2023-11-17T05:30:00.897631Z","iopub.execute_input":"2023-11-17T05:30:00.897908Z","iopub.status.idle":"2023-11-17T05:30:00.909175Z","shell.execute_reply.started":"2023-11-17T05:30:00.897883Z","shell.execute_reply":"2023-11-17T05:30:00.908270Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, GlobalMaxPooling2D, GlobalAveragePooling2D, Dense, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, BatchNormalization, Activation, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Activation, Concatenate, Conv2D, Multiply\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\n\ndef encoder(input_shape):\n    inputs = Input(shape=input_shape)\n\n    # Encoder\n    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n    conv1 = BatchNormalization()(conv1)\n    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n    conv3 = BatchNormalization()(conv3)\n    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    \n    #cbamMod = cbam(conv3)\n\n    return Model(inputs, [pool1,pool2,pool3])\n\ndef decoder(input_shape,encoded_features):\n    pool1,pool2,pool3 = encoded_features\n\n    up1 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(pool3)\n    up1 = cbam(up1)\n    merge1 = Concatenate()([pool2, up1])\n    conv4 = Conv2D(256, 3, activation='relu', padding='same')(merge1)\n    \n    up2 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv4)\n    up2 = cbam(up2)\n    merge2 = Concatenate()([pool1, up2])\n    conv5 = Conv2D(128, 3, activation='relu', padding='same')(merge2)\n\n\n    up3 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv5)\n    up3 = cbam(up3)\n    conv6 = Conv2D(64, 3, activation='relu', padding='same')(up3)\n\n    decoded = Conv2D(1, (1,1), activation='sigmoid', padding='same')(conv6)\n    return decoded\n\ndef landslide_detection_autoencoder(input_shape):\n    input_img = Input(shape=input_shape, name='input')\n\n    encoder_model = encoder(input_shape)\n    encoded = encoder_model(input_img)\n\n    decoded = decoder(input_shape, encoded)\n\n    return Model(inputs=input_img, outputs=decoded)\n\n# Training code for landslide detection using post images only\ninput_shape = (128, 128, 6)  # Update this to match your post image dimensions\nmodel = landslide_detection_autoencoder(input_shape)\n\nopt = tf.keras.optimizers.Adam(learning_rate=0.001)\n\nmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', f1_m, precision_m, recall_m])\n\nmodel.summary()","metadata":{"id":"FINpbRQpUXV2","execution":{"iopub.status.busy":"2023-11-17T05:30:00.910620Z","iopub.execute_input":"2023-11-17T05:30:00.910956Z","iopub.status.idle":"2023-11-17T05:30:02.113063Z","shell.execute_reply.started":"2023-11-17T05:30:00.910929Z","shell.execute_reply":"2023-11-17T05:30:02.112133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model = unet_model(128, 128, 6)\n# model.summary()\ncheckpointer = tf.keras.callbacks.ModelCheckpoint(\"best_model.h5\", monitor=\"val_f1_m\", verbose=1, save_best_only=True, mode=\"max\")\n# earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_f1_m', patience=10, verbose=1, mode='max')\n\ncallbacks = [\n    # earlyStopping,\n    checkpointer\n    ]\nhistory = model.fit(x_train, y_train, batch_size=16,\n          epochs=45,\n          verbose = 2,\n          validation_data=(x_valid, y_valid),\n          callbacks=callbacks)\n\nmodel.save(\"model_save.h5\")","metadata":{"id":"r12-i9HcPTz5","outputId":"e9018cbf-0615-46b5-90e8-9004e63861fa","execution":{"iopub.status.busy":"2023-11-17T05:30:02.123373Z","iopub.execute_input":"2023-11-17T05:30:02.123678Z","iopub.status.idle":"2023-11-17T05:50:22.303560Z","shell.execute_reply.started":"2023-11-17T05:30:02.123653Z","shell.execute_reply":"2023-11-17T05:50:22.302472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, accuracy, f1_score, precision, recall = model.evaluate(x_valid, y_valid, verbose=0)\nprint(loss, accuracy, f1_score, precision, recall)","metadata":{"id":"XYHLlzlgQ0QD","execution":{"iopub.status.busy":"2023-11-17T05:50:22.304992Z","iopub.execute_input":"2023-11-17T05:50:22.305285Z","iopub.status.idle":"2023-11-17T05:50:29.577291Z","shell.execute_reply.started":"2023-11-17T05:50:22.305262Z","shell.execute_reply":"2023-11-17T05:50:29.575993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,((ax11,ax12),(ax13,ax14)) = plt.subplots(2,2,figsize=(20,15))\nax11.plot(history.history['loss'])\nax11.plot(history.history['val_loss'])\nax11.title.set_text('model loss')\nax11.set_ylabel('loss')\nax11.set_xlabel('epoch')\nax11.legend(['train', 'validation'], loc='upper left')\n\nax12.plot(history.history['precision_m'])\nax12.plot(history.history['val_precision_m'])\nax12.set_title('model precision')\nax12.set_ylabel('precision')\nax12.set_xlabel('epoch')\nax12.legend(['train', 'validation'], loc='upper left')\n\nax13.plot(history.history['recall_m'])\nax13.plot(history.history['val_recall_m'])\nax13.set_title('model recall')\nax13.set_ylabel('recall')\nax13.set_xlabel('epoch')\nax13.legend(['train', 'validation'], loc='upper left')\n\nax14.plot(history.history['f1_m'])\nax14.plot(history.history['val_f1_m'])\nax14.set_title('model f1')\nax14.set_ylabel('f1')\nax14.set_xlabel('epoch')\nax14.legend(['train', 'validation'], loc='upper left')","metadata":{"id":"GG3PNakqVmHA","execution":{"iopub.status.busy":"2023-11-17T05:50:29.578584Z","iopub.execute_input":"2023-11-17T05:50:29.578931Z","iopub.status.idle":"2023-11-17T05:50:30.723385Z","shell.execute_reply.started":"2023-11-17T05:50:29.578899Z","shell.execute_reply":"2023-11-17T05:50:30.722477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold = 0.25\npred_img = model.predict(x_valid)\n#print(pred_img)\npred_img = (pred_img > threshold).astype(np.uint8)\n#print(pred_img[0])","metadata":{"id":"-Bp3c1GBbh-J","execution":{"iopub.status.busy":"2023-11-17T05:50:30.724699Z","iopub.execute_input":"2023-11-17T05:50:30.725028Z","iopub.status.idle":"2023-11-17T05:50:33.803934Z","shell.execute_reply.started":"2023-11-17T05:50:30.724999Z","shell.execute_reply":"2023-11-17T05:50:33.803010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# img = 115\n# fig,(ax1,ax2,ax3)= plt.subplots(1,3,figsize=(15,10))\n# ax1.imshow(pred_img[img, :, :, 0])\n# ax1.set_title(\"Predictions\")\n# ax2.imshow(y_valid[img, :, :, 0])\n# ax2.set_title(\"Label\")\n# ax3.imshow(x_valid[img, :, :, 0:3])\n# ax3.set_title('Training Image')","metadata":{"id":"2d0gC4y6cuLF","execution":{"iopub.status.busy":"2023-11-17T05:50:33.805182Z","iopub.execute_input":"2023-11-17T05:50:33.805514Z","iopub.status.idle":"2023-11-17T05:50:33.809782Z","shell.execute_reply.started":"2023-11-17T05:50:33.805473Z","shell.execute_reply":"2023-11-17T05:50:33.808853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Assuming 'pred_img' contains prediction maps, 'y_valid' contains labels, and 'x_valid' contains training images.\n\nimg = 146\n\n# Assuming you have already thresholded 'pred_img' to obtain a binary mask.\n# If not, you can threshold it as mentioned in the previous answer.\n\nprediction_binary_mask = pred_img[img, :, :, 0]\n\n# Create a colormap for highlighting\ncmap = plt.cm.get_cmap(\"viridis\")  # You can choose a different colormap\n\n# Create subplots\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 10))\n\n# Display predictions\nax1.imshow(pred_img[img, :, :, 0], cmap=cmap)\nax1.set_title(\"Predictions\")\n\n# Display labels\nax2.imshow(y_valid[img, :, :, 0], cmap=cmap)\nax2.set_title(\"Label\")\n\n# Display the training image with highlighted regions\ntraining_image = x_valid[img, :, :, 0:3].copy()\ntraining_image[prediction_binary_mask == 1] = [255, 0, 0]  # Highlight in red\nax3.imshow(training_image)\nax3.set_title(\"Training Image with Highlighted Regions\")\n\n# Show the plots\nplt.show()\n","metadata":{"id":"IowMbH1DdYXs","execution":{"iopub.status.busy":"2023-11-17T05:50:33.811218Z","iopub.execute_input":"2023-11-17T05:50:33.811980Z","iopub.status.idle":"2023-11-17T05:50:34.544247Z","shell.execute_reply.started":"2023-11-17T05:50:33.811943Z","shell.execute_reply":"2023-11-17T05:50:34.543293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming 'pred_img' contains prediction maps, 'y_valid' contains labels, and 'x_valid' contains training images.\n\nimg = 150\n\n# Assuming you have already thresholded 'pred_img' to obtain a binary mask.\n# If not, you can threshold it as mentioned in the previous answer.\n\nprediction_binary_mask = pred_img[img, :, :, 0]\n\n# Create a colormap for highlighting\ncmap = plt.cm.get_cmap(\"viridis\")  # You can choose a different colormap\n\n# Create subplots\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 10))\n\n# Display predictions\nax1.imshow(pred_img[img, :, :, 0], cmap=cmap)\nax1.set_title(\"Predictions\")\n\n# Display labels\nax2.imshow(y_valid[img, :, :, 0], cmap=cmap)\nax2.set_title(\"Label\")\n\n# Display the training image with highlighted regions\ntraining_image = x_valid[img, :, :, 0:3].copy()\ntraining_image[prediction_binary_mask == 1] = [255, 0, 0]  # Highlight in red\nax3.imshow(training_image)\nax3.set_title(\"Training Image with Highlighted Regions\")\n\n# Show the plots\nplt.show()\n","metadata":{"id":"c-XIlPh9dn8T","execution":{"iopub.status.busy":"2023-11-17T05:50:34.550460Z","iopub.execute_input":"2023-11-17T05:50:34.551152Z","iopub.status.idle":"2023-11-17T05:50:35.283338Z","shell.execute_reply.started":"2023-11-17T05:50:34.551116Z","shell.execute_reply":"2023-11-17T05:50:35.282451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming 'pred_img' contains prediction maps, 'y_valid' contains labels, and 'x_valid' contains training images.\n\nimg = 108\n\n# Assuming you have already thresholded 'pred_img' to obtain a binary mask.\n# If not, you can threshold it as mentioned in the previous answer.\n\nprediction_binary_mask = pred_img[img, :, :, 0]\n\n# Create a colormap for highlighting\ncmap = plt.cm.get_cmap(\"viridis\")  # You can choose a different colormap\n\n# Create subplots\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 10))\n\n# Display predictions\nax1.imshow(pred_img[img, :, :, 0], cmap=cmap)\nax1.set_title(\"Predictions\")\n\n# Display labels\nax2.imshow(y_valid[img, :, :, 0], cmap=cmap)\nax2.set_title(\"Label\")\n\n# Display the training image with highlighted regions\ntraining_image = x_valid[img, :, :, 0:3].copy()\ntraining_image[prediction_binary_mask == 1] = [255, 0, 0]  # Highlight in red\nax3.imshow(training_image)\nax3.set_title(\"Training Image with Highlighted Regions\")\n\n# Show the plots\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-17T05:50:35.284719Z","iopub.execute_input":"2023-11-17T05:50:35.285116Z","iopub.status.idle":"2023-11-17T05:50:36.046543Z","shell.execute_reply.started":"2023-11-17T05:50:35.285082Z","shell.execute_reply":"2023-11-17T05:50:36.045629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming 'pred_img' contains prediction maps, 'y_valid' contains labels, and 'x_valid' contains training images.\n\nimg = 27\n\n# Assuming you have already thresholded 'pred_img' to obtain a binary mask.\n# If not, you can threshold it as mentioned in the previous answer.\n\nprediction_binary_mask = pred_img[img, :, :, 0]\n\n# Create a colormap for highlighting\ncmap = plt.cm.get_cmap(\"viridis\")  # You can choose a different colormap\n\n# Create subplots\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 10))\n\n# Display predictions\nax1.imshow(pred_img[img, :, :, 0], cmap=cmap)\nax1.set_title(\"Predictions\")\n\n# Display labels\nax2.imshow(y_valid[img, :, :, 0], cmap=cmap)\nax2.set_title(\"Label\")\n\n# Display the training image with highlighted regions\ntraining_image = x_valid[img, :, :, 0:3].copy()\ntraining_image[prediction_binary_mask == 1] = [255, 0, 0]  # Highlight in red\nax3.imshow(training_image)\nax3.set_title(\"Training Image with Highlighted Regions\")\n\n# Show the plots\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-17T05:50:36.047893Z","iopub.execute_input":"2023-11-17T05:50:36.048547Z","iopub.status.idle":"2023-11-17T05:50:36.817346Z","shell.execute_reply.started":"2023-11-17T05:50:36.048502Z","shell.execute_reply":"2023-11-17T05:50:36.816461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming 'pred_img' contains prediction maps, 'y_valid' contains labels, and 'x_valid' contains training images.\n\nimg = 96\n\n# Assuming you have already thresholded 'pred_img' to obtain a binary mask.\n# If not, you can threshold it as mentioned in the previous answer.\n\nprediction_binary_mask = pred_img[img, :, :, 0]\n\n# Create a colormap for highlighting\ncmap = plt.cm.get_cmap(\"viridis\")  # You can choose a different colormap\n\n# Create subplots\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 10))\n\n# Display predictions\nax1.imshow(pred_img[img, :, :, 0], cmap=cmap)\nax1.set_title(\"Predictions\")\n\n# Display labels\nax2.imshow(y_valid[img, :, :, 0], cmap=cmap)\nax2.set_title(\"Label\")\n\n# Display the training image with highlighted regions\ntraining_image = x_valid[img, :, :, 0:3].copy()\ntraining_image[prediction_binary_mask == 1] = [255, 0, 0]  # Highlight in red\nax3.imshow(training_image)\nax3.set_title(\"Training Image with Highlighted Regions\")\n\n# Show the plots\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-17T05:50:36.818813Z","iopub.execute_input":"2023-11-17T05:50:36.819105Z","iopub.status.idle":"2023-11-17T05:50:37.585441Z","shell.execute_reply.started":"2023-11-17T05:50:36.819069Z","shell.execute_reply":"2023-11-17T05:50:37.584439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming 'pred_img' contains prediction maps, 'y_valid' contains labels, and 'x_valid' contains training images.\n\nimg = 69\n\n# Assuming you have already thresholded 'pred_img' to obtain a binary mask.\n# If not, you can threshold it as mentioned in the previous answer.\n\nprediction_binary_mask = pred_img[img, :, :, 0]\n\n# Create a colormap for highlighting\ncmap = plt.cm.get_cmap(\"viridis\")  # You can choose a different colormap\n\n# Create subplots\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 10))\n\n# Display predictions\nax1.imshow(pred_img[img, :, :, 0], cmap=cmap)\nax1.set_title(\"Predictions\")\n\n# Display labels\nax2.imshow(y_valid[img, :, :, 0], cmap=cmap)\nax2.set_title(\"Label\")\n\n# Display the training image with highlighted regions\ntraining_image = x_valid[img, :, :, 0:3].copy()\ntraining_image[prediction_binary_mask == 1] = [255, 0, 0]  # Highlight in red\nax3.imshow(training_image)\nax3.set_title(\"Training Image with Highlighted Regions\")\n\n# Show the plots\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-17T05:50:37.586812Z","iopub.execute_input":"2023-11-17T05:50:37.587199Z","iopub.status.idle":"2023-11-17T05:50:38.319813Z","shell.execute_reply.started":"2023-11-17T05:50:37.587165Z","shell.execute_reply":"2023-11-17T05:50:38.318924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}