{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6970778,"sourceType":"datasetVersion","datasetId":4005048}],"dockerImageVersionId":30580,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install tensorflow","metadata":{"id":"ty-4hAzq3cEL","outputId":"d9b2db51-b11c-4f2d-8827-afe11b9c6ab2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install matplotlib","metadata":{"id":"Wt2rwZ803he4","outputId":"9b6c702f-f9fa-4f18-b21e-cc59f48862d3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport h5py\nimport glob\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport tensorflow as tf","metadata":{"id":"j5lT58T03kfj","execution":{"iopub.status.busy":"2023-11-17T04:49:08.715147Z","iopub.execute_input":"2023-11-17T04:49:08.716011Z","iopub.status.idle":"2023-11-17T04:49:21.909480Z","shell.execute_reply.started":"2023-11-17T04:49:08.715975Z","shell.execute_reply":"2023-11-17T04:49:21.908303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_single = r\"/kaggle/input/landslide-data/img/image_2000.h5\"\npath_single_mask = r'/kaggle/input/landslide-data/mask/mask_2000.h5'","metadata":{"id":"FC3cTnUA8q0G","execution":{"iopub.status.busy":"2023-11-17T04:49:21.911744Z","iopub.execute_input":"2023-11-17T04:49:21.912546Z","iopub.status.idle":"2023-11-17T04:49:21.917189Z","shell.execute_reply.started":"2023-11-17T04:49:21.912504Z","shell.execute_reply":"2023-11-17T04:49:21.916367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f_data = np.zeros((1, 128,128, 3))\nwith h5py.File(path_single) as hdf:\n    ls = list(hdf.keys())\n    print(\"ls\", ls)\n    data = np.array(hdf.get('img'))\n    print(\"input data shape:\", data.shape)\n    plt.imshow(data[:, :, 3:0:-1])\n    plt.show()\n\n    data_red = data[:, :, 3]\n    data_green = data[:, :, 2]\n    data_blue = data[:, :, 1]\n    data_nir = data[:, :, 7]\n    data_rgb = data[:, :, 3:0:-1]\n    data_ndvi = np.divide(data_nir - data_red,np.add(data_nir, data_red))\n    f_data[0, :, :, 0] =data_ndvi\n    f_data[0, :, :, 1] = data[:, :, 12]\n    f_data[0, :, :, 2] = data[:, :, 13]\n\n    print(\"data ndvi shape \", data_ndvi.shape, \"f_data shape: \", f_data.shape)\n    plt.imshow(data_ndvi)","metadata":{"id":"hgodWtKV85YQ","outputId":"924c1c98-bea9-4676-bbf2-f19c153dc959","execution":{"iopub.status.busy":"2023-11-17T04:49:21.918364Z","iopub.execute_input":"2023-11-17T04:49:21.926347Z","iopub.status.idle":"2023-11-17T04:49:22.819426Z","shell.execute_reply.started":"2023-11-17T04:49:21.926302Z","shell.execute_reply":"2023-11-17T04:49:22.818320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with h5py.File(path_single_mask) as hdf:\n    ls = list(hdf.keys())\n    print(\"ls\", ls)\n    data = np.array(hdf.get('mask'))\n    print(\"input data shape:\", data.shape)\n    plt.imshow(data)","metadata":{"id":"DdR8XEWx_EeN","outputId":"b7634223-4128-4685-9d69-e42e0ed1b958","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_PATH = r\"/kaggle/input/landslide-data/img/*.h5\"\nTRAIN_MASK = r'/kaggle/input/landslide-data/mask/*.h5'\n\nTRAIN_XX = np.zeros((3799, 128, 128, 6))\nTRAIN_YY = np.zeros((3799, 128, 128, 1))\nall_train = sorted(glob.glob(TRAIN_PATH))\nall_mask = sorted(glob.glob(TRAIN_MASK))","metadata":{"id":"9_UylP8sBu3e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#testing for google colab GPU\nimport tensorflow as tf\ntf.test.gpu_device_name()","metadata":{"id":"HAyoe99ZGh7d","outputId":"49423eec-dba9-435e-e0f6-0c3c8c206c59","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, (img, mask) in enumerate(zip(all_train, all_mask)):\n    #print(i, img, mask)\n    with h5py.File(img) as hdf:\n        ls = list(hdf.keys())\n        data = np.array(hdf.get('img'))\n\n        # assign 0 for the nan value\n        data[np.isnan(data)] = 0.000001\n\n        # to normalize the data\n        mid_rgb = data[:, :, 1:4].max() / 2.0\n        mid_slope = data[:, :, 12].max() / 2.0\n        mid_elevation = data[:, :, 13].max() / 2.0\n\n        # ndvi calculation\n        data_red = data[:, :, 3]\n        data_nir = data[:, :, 7]\n        data_ndvi = np.divide(data_nir - data_red,np.add(data_nir, data_red))\n\n        # final array\n        TRAIN_XX[i, :, :, 0] = 1 - data[:, :, 3] / mid_rgb  #RED\n        TRAIN_XX[i, :, :, 1] = 1 - data[:, :, 2] / mid_rgb #GREEN\n        TRAIN_XX[i, :, :, 2] = 1 - data[:, :, 1] / mid_rgb #BLUE\n        TRAIN_XX[i, :, :, 3] = data_ndvi #NDVI\n        TRAIN_XX[i, :, :, 4] = 1 - data[:, :, 12] / mid_slope #SLOPE\n        TRAIN_XX[i, :, :, 5] = 1 - data[:, :, 13] / mid_elevation #ELEVATION\n\n\n    with h5py.File(mask) as hdf:\n        ls = list(hdf.keys())\n        data=np.array(hdf.get('mask'))\n        #plt.imshow(data)\n        #plt.show()\n        TRAIN_YY[i, :, :, 0] = data\n","metadata":{"id":"Yyg0Xsw-HUPw","outputId":"683ceab2-0839-4fb2-8edf-d24b162d22d3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_XX[np.isnan(TRAIN_XX)] = 0.000001\nprint(TRAIN_XX.min(), TRAIN_XX.max(), TRAIN_YY.min(), TRAIN_YY.max())","metadata":{"id":"uRQd3iYvJqax","outputId":"03c374c1-731d-414e-dae0-2c4939817bc1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dice_loss(y_true, y_pred):\n  y_true = tf.cast(y_true, tf.float32)\n  y_pred = tf.math.sigmoid(y_pred)\n  numerator = 2 * tf.reduce_sum(y_true * y_pred)\n  denominator = tf.reduce_sum(y_true + y_pred)\n\n  return 1 - (numerator / denominator)","metadata":{"id":"PYSapN-rUscr","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img=234\nfig,(ax1,ax2, ax3, ax4, ax5)= plt.subplots(1,5,figsize=(15,10))\n\n\nax1.set_title(\"RGB image\")\nax2.set_title(\"NDVI\")\nax3.set_title(\"Slope\")\nax4.set_title(\"Elevation\")\nax5.set_title(\"Mask\")\nax1.imshow(TRAIN_XX[img, :, :, 0:3])\nax2.imshow(TRAIN_XX[img, :, :, 3])\nax3.imshow(TRAIN_XX[img, :, :, 4])\nax4.imshow(TRAIN_XX[img, :, :, 5])\nax5.imshow(TRAIN_YY[img, :, :, 0])","metadata":{"id":"4TEBmPoKpwmj","outputId":"de9eb3d7-c30a-4b9d-bb88-1e39e337d0ae","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note: Learn about NDVI, Slope and Elevation properly, Something is going wrong in thw split!!","metadata":{"id":"hltzGw3qqAYx"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split the data\nx_train, x_valid, y_train, y_valid = train_test_split(TRAIN_XX, TRAIN_YY, test_size=0.2, shuffle= True, random_state=42)","metadata":{"id":"hp0Auy6IqGZY","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img=1548\nfig,(ax1,ax2, ax3, ax4, ax5)= plt.subplots(1,5,figsize=(15,10))\n\nax1.set_title(\"RGB image\")\nax2.set_title(\"NDVI\")\nax3.set_title(\"Slope\")\nax4.set_title(\"Elevation\")\nax5.set_title(\"Mask\")\nax1.imshow(x_train[img, :, :, 0:3])\nax2.imshow(x_train[img, :, :, 3])\nax3.imshow(x_train[img, :, :, 4])\nax4.imshow(x_train[img, :, :, 5])\nax5.imshow(y_train[img, :, :, 0])","metadata":{"id":"O-0JOB_sqQos","outputId":"04f53fef-2ce3-477c-95d9-d1e7ae3f54af","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.shape, y_train.shape","metadata":{"id":"P9Eag16RqY-P","outputId":"509a767b-8cc2-4f88-8a29-a292dca99765","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to release some memory, delete the unnecessary variable\ndel TRAIN_XX\ndel TRAIN_YY\ndel all_train\ndel all_mask","metadata":{"id":"pQ3VwqNnqd07","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img=1548\nfig,(ax1,ax2, ax3, ax4)= plt.subplots(1,4,figsize=(15,10))\n\n\nax1.set_title(\"RGB image\")\nax2.set_title(\"NDVI\")\nax3.set_title(\"SLOPE\")\nax4.set_title(\"Mask\")\nax1.imshow(x_train[img, :, :, 0:3])\nax2.imshow(x_train[img, :, :, 3])\nax3.imshow(x_train[img, :, :, 4])\nax4.imshow(y_train[img, :, :, 0])","metadata":{"id":"mUenSLqbqllR","outputId":"e9b9c0e4-2a74-47b7-ff9d-00cf5655610b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import backend as K\n\n# recall\ndef recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n\n# precision\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n\n#f1 score\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","metadata":{"id":"31QADv5hQOhK","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import tensorflow as tf\n# from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, BatchNormalization, Activation, Dropout\n# from tensorflow.keras.models import Model\n# from tensorflow.keras.optimizers import Adam\n# import numpy as np\n\n# def encoder(input_shape):\n#     inputs = Input(shape=input_shape)\n\n#     # Encoder\n#     conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n#     conv1 = BatchNormalization()(conv1)\n#     conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n#     pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n#     conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n#     conv2 = BatchNormalization()(conv2)\n#     conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n#     pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n#     conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n#     conv3 = BatchNormalization()(conv3)\n#     conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n#     pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n#     return Model(inputs, [pool1,pool2,pool3])\n\n# def decoder(input_shape,encoded_features):\n#     pool1,pool2,pool3 = encoded_features\n\n#     up1 = UpSampling2D(size=(2, 2))(pool3)\n#     merge1 = Concatenate()([pool2, up1])\n#     conv4 = Conv2D(256, 3, activation='relu', padding='same')(merge1)\n\n#     up2 = UpSampling2D(size=(2, 2))(conv4)\n#     merge2 = Concatenate()([pool1, up2])\n#     conv5 = Conv2D(128, 3, activation='relu', padding='same')(merge2)\n\n#     up3 = UpSampling2D(size=(2, 2))(conv5)\n#     conv6 = Conv2D(64, 3, activation='relu', padding='same')(up3)\n\n#     decoded = Conv2D(1, (1,1), activation='sigmoid', padding='same')(conv6)\n#     return decoded\n\n# def landslide_detection_autoencoder(input_shape):\n#     input_img = Input(shape=input_shape, name='input')\n\n#     encoder_model = encoder(input_shape)\n#     encoded = encoder_model(input_img)\n\n#     decoded = decoder(input_shape, encoded)\n\n#     return Model(inputs=input_img, outputs=decoded)\n\n# # Training code for landslide detection using post images only\n# input_shape = (128, 128, 6)  # Update this to match your post image dimensions\n# model = landslide_detection_autoencoder(input_shape)\n\n# opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n\n# model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', f1_m, precision_m, recall_m])\n\n# model.summary()\n\n# # history = model.fit(post_images,  # Input: post images only\n# #                     landslide_labels,  # Target: landslide labels (binary)\n# #                     batch_size=32,\n# #                     epochs=135,\n# #                     validation_split=0.2)\n","metadata":{"id":"NIllz3TFInJy","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import tensorflow as tf\n# from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, BatchNormalization, Activation, Dropout\n# from tensorflow.keras.models import Model\n# from tensorflow.keras.optimizers import Adam\n# import numpy as np\n\n# def encoder(input_shape):\n#     inputs = Input(shape=input_shape)\n\n#     # Encoder\n#     conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n#     conv1 = BatchNormalization()(conv1)\n#     conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n#     pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n#     conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n#     conv2 = BatchNormalization()(conv2)\n#     conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n#     pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n#     conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n#     conv3 = BatchNormalization()(conv3)\n#     conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n#     pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n#     return Model(inputs, [pool1,pool2,pool3])\n\n# def decoder(input_shape,encoded_features):\n#     pool1,pool2,pool3 = encoded_features\n\n#     up1 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(pool3)\n#     merge1 = Concatenate()([pool2, up1])\n#     conv4 = Conv2D(256, 3, activation='relu', padding='same')(merge1)\n\n#     up2 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv4)\n#     merge2 = Concatenate()([pool1, up2])\n#     conv5 = Conv2D(128, 3, activation='relu', padding='same')(merge2)\n\n\n#     up3 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv5)\n#     conv6 = Conv2D(64, 3, activation='relu', padding='same')(up3)\n\n#     decoded = Conv2D(1, (1,1), activation='sigmoid', padding='same')(conv6)\n#     return decoded\n\n# def landslide_detection_autoencoder(input_shape):\n#     input_img = Input(shape=input_shape, name='input')\n\n#     encoder_model = encoder(input_shape)\n#     encoded = encoder_model(input_img)\n\n#     decoded = decoder(input_shape, encoded)\n\n#     return Model(inputs=input_img, outputs=decoded)\n\n# # Training code for landslide detection using post images only\n# input_shape = (128, 128, 6)  # Update this to match your post image dimensions\n# model = landslide_detection_autoencoder(input_shape)\n\n# opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n\n# model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', f1_m, precision_m, recall_m])\n\n# model.summary()","metadata":{"id":"FINpbRQpUXV2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#With extra layers \"FINAL\".\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, BatchNormalization, Activation, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\n\ninitializer = tf.keras.initializers.HeNormal()\n\ndef encoder(input_shape):\n    inputs = Input(shape=input_shape)\n\n    inputs = Input(shape=input_shape)\n\n    conv0 = Conv2D(32, 3, activation='relu',  padding='same')(inputs)\n    conv0 = Conv2D(32, 3, activation='relu',  padding='same')(conv0)\n    conv0 = BatchNormalization()(conv0)\n    conv0 = Dropout(0.2)(conv0)\n    pool0 = MaxPooling2D(pool_size=(2, 2))(conv0)\n\n    conv1 = Conv2D(64, 3, activation='relu',  padding='same')(pool0)\n    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n    conv1 = BatchNormalization()(conv1)\n    conv1 = Dropout(0.2)(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n    conv2 = Conv2D(128, 3, activation='relu',  padding='same')(pool1)\n    conv2 = Conv2D(128, 3, activation='relu',  padding='same')(conv2)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = Dropout(0.2)(conv2)\n    conv2 = Conv2D(128, 3, activation='relu',   padding='same')(conv2)\n    conv2 = Conv2D(128, 3, activation='relu',  padding='same')(conv2)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = Dropout(0.2)(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n    conv3 = Conv2D(256, 3, activation='relu',  padding='same')(pool2)\n    conv3 = Conv2D(256, 3, activation='relu',  padding='same')(conv3)\n    conv3 = BatchNormalization()(conv3)\n    conv3 = Dropout(0.3)(conv3)\n    conv3 = Conv2D(256, 3, activation='relu',  padding='same')(conv3)\n    conv3 = Conv2D(256, 3, activation='relu',  padding='same')(conv3)\n    conv3 = BatchNormalization()(conv3)\n    conv3 = Dropout(0.3)(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n    # Add more convolutional layers as needed\n    conv4 = Conv2D(512, 3, activation='relu',  padding='same')(pool3)\n    conv4 = BatchNormalization()(conv4)\n    conv4 = Conv2D(512, 3, activation='relu',  padding='same')(conv4)\n    conv4 = BatchNormalization()(conv4)\n    conv4 = Dropout(0.3)(conv4)\n\n\n    return Model(inputs, [conv0,conv1,conv2,conv3,conv4])\n\ndef decoder(input_shape,encoded_features):\n  conv0,conv1,conv2,conv3,conv4 = encoded_features\n\n  up1 = tf.keras.layers.Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same')(conv4)\n  merge2 = Concatenate()([conv3, up1])\n  conv5 = Conv2D(256, 3, activation='relu',  padding='same')(merge2)\n  conv5= Dropout(0.3)(conv5)\n  conv5 = Conv2D(256, 3, activation='relu', padding='same')(conv5)\n\n\n  up2 = tf.keras.layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(conv5)\n  merge3 = Concatenate()([conv2, up2])\n  conv6 = Conv2D(128, 3, activation='relu',   padding='same')(merge3)\n  conv6= Dropout(0.2)(conv6)\n  conv6 = Conv2D(256, 3, activation='relu',  padding='same')(conv6)\n\n  up3 = tf.keras.layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')(conv6)\n  merge4 = Concatenate()([conv1, up3])\n  conv7 = Conv2D(64, 3, activation='relu', padding='same')(merge4)\n  conv7= Dropout(0.1)(conv7)\n  conv7 = Conv2D(64, 3, activation='relu',  padding='same')(conv7)\n\n  up4 = tf.keras.layers.Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same')(conv7)\n  merge5 = Concatenate()([conv0, up4])\n  conv8 = Conv2D(32, 3, activation='relu',  padding='same')(merge5)\n  conv8= Dropout(0.1)(conv8)\n  conv8 = Conv2D(32, 3, activation='relu',  padding='same')(conv8)\n\n  decoded = Conv2D(1, (1,1), activation='sigmoid', padding='same')(conv8)\n  return decoded\n\ndef landslide_detection_autoencoder(input_shape):\n    input_img = Input(shape=input_shape, name='input')\n\n    encoder_model = encoder(input_shape)\n    encoded = encoder_model(input_img)\n\n    decoded = decoder(input_shape, encoded)\n\n    return Model(inputs=input_img, outputs=decoded)\n\n# Training code for landslide detection using post images only\ninput_shape = (128, 128, 6)  # Update this to match your post image dimensions\nmodel = landslide_detection_autoencoder(input_shape)\n\nopt = tf.keras.optimizers.Adam(learning_rate=0.001)\n\nmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', f1_m, precision_m, recall_m])\n\nmodel.summary()","metadata":{"id":"eFHeN9oTuq1D","outputId":"c7f4b73a-5c84-4359-dfb5-a4d7d0c9819c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def unet_model(IMG_WIDTH, IMG_HIGHT, IMG_CHANNELS):\n#     inputs = tf.keras.layers.Input((IMG_WIDTH, IMG_HIGHT, IMG_CHANNELS))\n\n#     # Converted inputs to floating\n#     #s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n\n\n#     #Contraction path\n#     c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n#     c1 = tf.keras.layers.Dropout(0.1)(c1)\n#     c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n#     p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n\n#     c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n#     c2 = tf.keras.layers.Dropout(0.1)(c2)\n#     c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n#     p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n\n#     c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n#     c3 = tf.keras.layers.Dropout(0.2)(c3)\n#     c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n#     p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n\n#     c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n#     c4 = tf.keras.layers.Dropout(0.2)(c4)\n#     c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n#     p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n\n#     c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n#     c5 = tf.keras.layers.Dropout(0.3)(c5)\n#     c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n\n#     #Expansive path\n#     u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n#     u6 = tf.keras.layers.concatenate([u6, c4])\n#     c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n#     c6 = tf.keras.layers.Dropout(0.2)(c6)\n#     c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n\n#     u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n#     u7 = tf.keras.layers.concatenate([u7, c3])\n#     c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n#     c7 = tf.keras.layers.Dropout(0.2)(c7)\n#     c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n\n#     u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n#     u8 = tf.keras.layers.concatenate([u8, c2])\n#     c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n#     c8 = tf.keras.layers.Dropout(0.1)(c8)\n#     c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n\n#     u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n#     u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n#     c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n#     c9 = tf.keras.layers.Dropout(0.1)(c9)\n#     c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n\n#     outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n\n#     model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', f1_m, precision_m, recall_m])\n\n#     return model","metadata":{"id":"alKHGBkNqnwL","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model = unet_model(128, 128, 6)\n# model.summary()\ncheckpointer = tf.keras.callbacks.ModelCheckpoint(\"best_model.h5\", monitor=\"val_f1_m\", verbose=1, save_best_only=True, mode=\"max\")\n# earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_f1_m', patience=10, verbose=1, mode='max')\n\ncallbacks = [\n    # earlyStopping,\n    checkpointer\n    ]\nhistory = model.fit(x_train, y_train, batch_size=16,\n          epochs=130,\n          verbose = 2,\n          validation_data=(x_valid, y_valid),\n          callbacks=callbacks)\n\nmodel.save(\"model_save.h5\")","metadata":{"id":"r12-i9HcPTz5","outputId":"e9018cbf-0615-46b5-90e8-9004e63861fa","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, accuracy, f1_score, precision, recall = model.evaluate(x_valid, y_valid, verbose=0)\nprint(loss, accuracy, f1_score, precision, recall)","metadata":{"id":"XYHLlzlgQ0QD","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,((ax11,ax12),(ax13,ax14)) = plt.subplots(2,2,figsize=(20,15))\nax11.plot(history.history['loss'])\nax11.plot(history.history['val_loss'])\nax11.title.set_text('model loss')\nax11.set_ylabel('loss')\nax11.set_xlabel('epoch')\nax11.legend(['train', 'validation'], loc='upper left')\n\nax12.plot(history.history['precision_m'])\nax12.plot(history.history['val_precision_m'])\nax12.set_title('model precision')\nax12.set_ylabel('precision')\nax12.set_xlabel('epoch')\nax12.legend(['train', 'validation'], loc='upper left')\n\nax13.plot(history.history['recall_m'])\nax13.plot(history.history['val_recall_m'])\nax13.set_title('model recall')\nax13.set_ylabel('recall')\nax13.set_xlabel('epoch')\nax13.legend(['train', 'validation'], loc='upper left')\n\nax14.plot(history.history['f1_m'])\nax14.plot(history.history['val_f1_m'])\nax14.set_title('model f1')\nax14.set_ylabel('f1')\nax14.set_xlabel('epoch')\nax14.legend(['train', 'validation'], loc='upper left')","metadata":{"id":"GG3PNakqVmHA","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# threshold = 0.2\n# pred_img = model.predict(x_valid)\n# #print(pred_img)\n# pred_img = (pred_img > threshold).astype(np.uint8)\n# #print(pred_img[0])","metadata":{"id":"-Bp3c1GBbh-J","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# img = 115\n# fig,(ax1,ax2,ax3)= plt.subplots(1,3,figsize=(15,10))\n# ax1.imshow(pred_img[img, :, :, 0])\n# ax1.set_title(\"Predictions\")\n# ax2.imshow(y_valid[img, :, :, 0])\n# ax2.set_title(\"Label\")\n# ax3.imshow(x_valid[img, :, :, 0:3])\n# ax3.set_title('Training Image')","metadata":{"id":"2d0gC4y6cuLF","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Assuming 'pred_img' contains prediction maps, 'y_valid' contains labels, and 'x_valid' contains training images.\n\nimg = 119\n\n# Assuming you have already thresholded 'pred_img' to obtain a binary mask.\n# If not, you can threshold it as mentioned in the previous answer.\n\nprediction_binary_mask = pred_img[img, :, :, 0]\n\n# Create a colormap for highlighting\ncmap = plt.cm.get_cmap(\"viridis\")  # You can choose a different colormap\n\n# Create subplots\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 10))\n\n# Display predictions\nax1.imshow(pred_img[img, :, :, 0], cmap=cmap)\nax1.set_title(\"Predictions\")\n\n# Display labels\nax2.imshow(y_valid[img, :, :, 0], cmap=cmap)\nax2.set_title(\"Label\")\n\n# Display the training image with highlighted regions\ntraining_image = x_valid[img, :, :, 0:3].copy()\ntraining_image[prediction_binary_mask == 1] = [255, 0, 0]  # Highlight in red\nax3.imshow(training_image)\nax3.set_title(\"Training Image with Highlighted Regions\")\n\n# Show the plots\nplt.show()\n","metadata":{"id":"IowMbH1DdYXs","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"c-XIlPh9dn8T"},"execution_count":null,"outputs":[]}]}